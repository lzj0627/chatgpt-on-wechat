# encoding:utf-8

import plugins
from bridge.context import ContextType
from bridge.reply import Reply, ReplyType
from common.log import logger
from plugins import *
from config import conf
from common.expired_dict import ExpiredDict
from common.cloudflare_r2 import CloudFlareR2
import base64
import openai
import openai.error
import time
import requests
import os


@plugins.register(
    name="Vision",
    desire_priority=-1,
    desc="A plugin that allows you to ask questions based on pictures",
    version="0.1",
    author="lzj",
)
class Vision(Plugin):
    def __init__(self):
        super().__init__()
        try:
            # è¿‡æœŸå­—å…¸å­˜æ”¾ä¸Šä¸‹æ–‡
            self.params_cache = ExpiredDict(3 * 60)
            self.handlers[Event.ON_HANDLE_CONTEXT] = self.on_handle_context
            openai.api_key = conf().get("open_ai_api_key")
            if conf().get("open_ai_api_base"):
                openai.api_base = conf().get("open_ai_api_base")
            proxy = conf().get("proxy")
            if proxy:
                openai.proxy = proxy
            self.args = {
                "model": "gpt-4-vision-preview",  # å¯¹è¯æ¨¡å‹çš„åç§°
                "temperature": conf().get("temperature", 0.9),  # å€¼åœ¨[0,1]ä¹‹é—´ï¼Œè¶Šå¤§è¡¨ç¤ºå›å¤è¶Šå…·æœ‰ä¸ç¡®å®šæ€§
                "max_tokens": 4096,  # å›å¤æœ€å¤§çš„å­—ç¬¦æ•°
                "top_p": conf().get("top_p", 1),
                "frequency_penalty": conf().get("frequency_penalty", 0.0),  # [-2,2]ä¹‹é—´ï¼Œè¯¥å€¼è¶Šå¤§åˆ™æ›´å€¾å‘äºäº§ç”Ÿä¸åŒçš„å†…å®¹
                "presence_penalty": conf().get("presence_penalty", 0.0),  # [-2,2]ä¹‹é—´ï¼Œè¯¥å€¼è¶Šå¤§åˆ™æ›´å€¾å‘äºäº§ç”Ÿä¸åŒçš„å†…å®¹
                "request_timeout": conf().get("request_timeout", None),  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œopenaiæ¥å£é»˜è®¤è®¾ç½®ä¸º600ï¼Œå¯¹äºéš¾é—®é¢˜ä¸€èˆ¬éœ€è¦è¾ƒé•¿æ—¶é—´
                "timeout": conf().get("request_timeout", None),  # é‡è¯•è¶…æ—¶æ—¶é—´ï¼Œåœ¨è¿™ä¸ªæ—¶é—´å†…ï¼Œå°†ä¼šè‡ªåŠ¨é‡è¯•
            }
            self.system_prompt = {"role": "system",
                                  "content": "You only need to identify the picture and only need to answer the last question, reply in Chinese."}
        except Exception as e:
            raise self.handle_error(e, "[Vision] init failed, ignore ")

    def on_handle_context(self, e_context: EventContext):
        context = e_context["context"]
        if context.type not in [
            ContextType.TEXT,
            ContextType.IMAGE
        ]:
            return
        if context.type == ContextType.TEXT:
            content = context.content.strip()
            if content.startswith('è¯†å›¾'):
                question = content[2:].strip()
                if question:
                    query = [{"type": "text", "text": question}]
                else:
                    query = [{"type": "text", "text": "Whatâ€™s in this image? Please answer me in Chinese."}]
                query_dict = {"has_image": False,
                              "query": query}
                if not self.params_cache.get(context.get('session_id')):
                    self.params_cache[context.get('session_id')] = query_dict
                reply = self.create_reply(ReplyType.TEXT, 'è¯·å‘é€ä¸€å¼ å›¾ç‰‡')
            elif content.startswith('è¯†å›¾æé—®'):
                user_context = self.params_cache.get(context.get('session_id'))
                if user_context and user_context.get('has_image'):
                    user_context_content = user_context.get('query')
                    question = content[4:].strip()
                    user_context_content.append({"type": "text", "text": question})
                    messages = [self.system_prompt, {"role": "user", "content": user_context_content}]
                    api_key = context.get("openai_api_key") or conf().get("open_ai_api_key")
                    reply_content = self.query_by_image(api_key, messages, self.args)
                    reply = self.create_reply(ReplyType.TEXT, reply_content['content'])
                else:
                    reply = self.create_reply(ReplyType.TEXT, 'æš‚æ— è¯†å›¾æ‰€éœ€ä¸Šä¸‹æ–‡ï¼Œè¯·å…ˆå‘é€â€œè¯†å›¾ + é—®é¢˜â€')
            elif content.startswith('é‡ç½®è¯†å›¾'):
                if self.params_cache.get(context.get('session_id')):
                    del self.params_cache[context.get('session_id')]
                reply = self.create_reply(ReplyType.TEXT, 'å¯ä»¥é‡æ–°è¯†å›¾å•¦')
            else:
                return
            e_context["reply"] = reply
            e_context.action = EventAction.BREAK_PASS
        elif self.params_cache.get(context.get('session_id')) and context.type == ContextType.IMAGE:
            context.get("msg").prepare()
            file_path = context.content
            # image_storage = open(file_path, 'rb')
            # image_storage.seek(0)
            # base64_image = base64.b64encode(image_storage.read()).decode('utf-8')
            # img_content = {"type": "image_url",
            #                 "image_url": {
            #                 "url": f"data:image/jpeg;base64,{base64_image}"}}
            
            cf_obj = CloudFlareR2()
            if not cf_obj.is_valid():
                reply = self.create_reply(ReplyType.TEXT, 'æ²¡æœ‰é…ç½®Cloudflare R2å¯¹è±¡å­˜å‚¨')
                e_context["reply"] = reply
                e_context.action = EventAction.BREAK_PASS
                return
            img_url = cf_obj.to_r2(file_path)
            img_content = {"type": "image_url",
                            "image_url": {
                            "url": img_url}}
            obj = self.params_cache.get(context.get('session_id'))
            obj['has_image'] = True
            # del self.params_cache[context.get('session_id')]
            obj.get('query').insert(1, img_content)
            user_content = obj.get('query')
            messages = [{"role": "user", "content": user_content}]
            # self.params_cache[context.get('session_id')] = gpt_content
            api_key = context.get("openai_api_key") or conf().get("open_ai_api_key")
            reply_content = self.query_by_image(api_key, messages, self.args)
            reply = self.create_reply(ReplyType.TEXT, reply_content['content'])
            e_context["reply"] = reply
            e_context.action = EventAction.BREAK_PASS
        else:
            return
        
    def create_reply(self, reply_type, content):
        reply = Reply()
        reply.type = reply_type
        reply.content = content
        return reply

    def get_help_text(self, **kwargs):
        help_text = "  ğŸ“¸ è¯†å›¾: å‘é€â€œè¯†å›¾+é—®é¢˜â€ï¼ŒéšåæŒ‰ç…§æç¤ºå‘é€ä¸€å¼ å›¾ç‰‡ï¼ŒGPTå°†ç»“åˆå›¾ç‰‡åŠæ‰€æé—®é¢˜è¿›è¡Œå›ç­” å¦‚â€œè¯†å›¾ å›¾ç‰‡ä¸­æœ‰ä»€ä¹ˆâ€ã€‚\n"
        help_text += "  ğŸ“¸ è¯†å›¾: å‘é€â€œè¯†å›¾æé—®+é—®é¢˜â€ï¼Œç»§ç»­æ‰€å‘å›¾ç‰‡è¿›è¡Œæé—®ã€‚\n"
        help_text += "  ğŸ“¸ è¯†å›¾: å‘é€â€œé‡ç½®è¯†å›¾â€ï¼Œç»“æŸå¯¹å½“å‰å›¾ç‰‡çš„æé—®ã€‚\n"
        return help_text

    def query_by_image(self, api_key, messages, args, retry_count=0):
        try:
            if conf().get("rate_limit_chatgpt") and not self.tb4chatgpt.get_token():
                raise openai.error.RateLimitError("RateLimitError: rate limit exceeded")
            # if api_key == None, the default openai.api_key will be used
            if args is None:
                args = self.args
            response = openai.ChatCompletion.create(api_key=api_key, messages=messages, **args)
            logger.debug("[CHATGPT] response={}".format(response))
            logger.info("[ChatGPT] reply={}, total_tokens={}".format(response.choices[0]['message']['content'], response["usage"]["total_tokens"]))
            return {
                "total_tokens": response["usage"]["total_tokens"],
                "completion_tokens": response["usage"]["completion_tokens"],
                "content": response.choices[0]["message"]["content"],
            }
        except Exception as e:
            need_retry = retry_count < 2
            result = {"completion_tokens": 0, "content": "æˆ‘ç°åœ¨æœ‰ç‚¹ç´¯äº†ï¼Œç­‰ä¼šå†æ¥å§"}
            if isinstance(e, openai.error.RateLimitError):
                logger.warn("[CHATGPT] RateLimitError: {}".format(e))
                result["content"] = "æé—®å¤ªå¿«å•¦ï¼Œè¯·ä¼‘æ¯ä¸€ä¸‹å†é—®æˆ‘å§"
                if need_retry:
                    time.sleep(20)
            elif isinstance(e, openai.error.Timeout):
                logger.warn("[CHATGPT] Timeout: {}".format(e))
                result["content"] = "æˆ‘æ²¡æœ‰æ”¶åˆ°ä½ çš„æ¶ˆæ¯"
                if need_retry:
                    time.sleep(5)
            elif isinstance(e, openai.error.APIError):
                logger.warn("[CHATGPT] Bad Gateway: {}".format(e))
                result["content"] = "è¯·å†é—®æˆ‘ä¸€æ¬¡"
                if need_retry:
                    time.sleep(10)
            elif isinstance(e, openai.error.APIConnectionError):
                logger.warn("[CHATGPT] APIConnectionError: {}".format(e))
                need_retry = False
                result["content"] = "æˆ‘è¿æ¥ä¸åˆ°ä½ çš„ç½‘ç»œ"
            else:
                logger.exception("[CHATGPT] Exception: {}".format(e))
                need_retry = False

            if need_retry:
                logger.warn("[CHATGPT] ç¬¬{}æ¬¡é‡è¯•".format(retry_count + 1))
                return self.query_by_image(api_key, messages, args, retry_count + 1)
            else:
                return result
            
